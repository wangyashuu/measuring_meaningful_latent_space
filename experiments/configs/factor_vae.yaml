model:
  name: "FactorVAE"
  input_shape: [3, 64, 64]
  latent_dim: 128
  hidden_channels: [16, 64, 256]
  tc_loss_factor: 10

data:
  name: "CelebA"

train:
  batch_size: 64

val:
  batch_size: 64

optimizers:
  - lr: 0.0001
    weight_decay: 0.0
  - lr: 0.0001
    model: "discriminator"
    weight_decay: 0.0

schedulers:
  - gamma: 0.95
  - gamma: 0.95

trainer:
  accelerator: "gpu"
  devices: [1, 3, 4, 5, 6]
  max_epochs: 8

logging:
  save_dir: "logs/"

metrics:
  includes: ["mig"]

seed: 12
