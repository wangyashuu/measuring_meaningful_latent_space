model:
  name: "BetaTCVAE"
  input_shape: [3, 64, 64]
  latent_dim: 64
  hidden_channels: [16, 64, 256, 512]
  mutual_info_loss_factor: 1.0
  tc_loss_factor: 2.0
  dimension_wise_kl_factor: 1.0
  minibatch_stratified_sampling: true
  train_set_size: 162770
  val_set_size: 19962
  # train_set_size: 589824
  # val_set_size: 147456

data:
  name: "CelebA"

train:
  batch_size: 128

val:
  batch_size: 128

optimizers:
  - lr: 0.0001
    weight_decay: 0.0

schedulers:
  - gamma: 0.95

trainer:
  accelerator: "gpu"
  devices: [1, 3, 4, 5, 6]
  max_epochs: 12

logging:
  save_dir: "logs/"

metrics:
  includes: ["mig"]

seed: 1265
