model:
  name: "BetaVAE"
  input_shape: [3, 64, 64]
  latent_dim: 8
  hidden_channels: [16, 64, 256]
  beta: 4

data:
  name: "CelebA"

train:
  batch_size: 64

val:
  batch_size: 64

optimizers:
  - lr: 0.0001
    weight_decay: 0.0

schedulers:
  - gamma: 0.95

trainer:
  accelerator: "gpu"
  devices: [1, 3, 4, 5, 6]
  max_epochs: 4

logging:
  save_dir: "logs/"

metrics:
  includes: ["mig"]

seed: 1265
