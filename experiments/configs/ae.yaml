model:
  name: "AE"
  input_shape: [3, 64, 64]
  latent_dim: 128
  hidden_channels: [16, 32, 64, 128, 256, 512]

data:
  name: "CelebA"

train:
  batch_size: 64

val:
  batch_size: 64

optimizers:
  - lr: 0.0001
    weight_decay: 0.0

schedulers:
  - gamma: 0.95

trainer:
  accelerator: "gpu"
  devices: [1, 3, 4, 5, 6]

logging:
  save_dir: "logs/"

seed: 1265
